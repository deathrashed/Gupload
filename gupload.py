#!/usr/bin/env python3import base64import datetime as dtimport hashlibimport jsonimport mimetypesimport osimport reimport subprocessimport sysimport timeimport urllib.requestimport urllib.errorCONFIG_PATH = os.path.expanduser("~/.config/ghuploader/config.json")def eprint(*a):    print(*a, file=sys.stderr)def load_config():    if not os.path.exists(CONFIG_PATH):        eprint(f"Missing config: {CONFIG_PATH}")        eprint("Create it from the example in the instructions.")        sys.exit(2)    with open(CONFIG_PATH, "r", encoding="utf-8") as f:        return json.load(f)def run(cmd):    return subprocess.check_output(cmd, text=True).strip()def get_token(cfg):    # Prefer env var, then `gh auth token`    for k in ("GITHUB_TOKEN", "GH_TOKEN"):        if os.environ.get(k):            return os.environ[k]    if cfg.get("allow_gh_cli_token", True):        try:            return run(["gh", "auth", "token"])        except Exception:            pass    eprint("No GitHub token found. Set GITHUB_TOKEN (recommended) or login via `gh auth login`.")    sys.exit(2)def api_request(method, url, token, data=None, headers=None):    h = {        "Accept": "application/vnd.github+json",        "Authorization": f"Bearer {token}",        "X-GitHub-Api-Version": "2022-11-28",        "User-Agent": "ghuploader",    }    if headers:        h.update(headers)    body = None    if data is not None:        body = json.dumps(data).encode("utf-8")        h["Content-Type"] = "application/json"    req = urllib.request.Request(url, data=body, headers=h, method=method)    try:        with urllib.request.urlopen(req) as resp:            raw = resp.read()            if raw:                return json.loads(raw.decode("utf-8"))            return None    except urllib.error.HTTPError as err:        msg = err.read().decode("utf-8", errors="replace")        raise RuntimeError(f"{method} {url} -> {err.code}\n{msg}") from Nonedef sanitize_filename(name):    # Keep extension; make filename Obsidian-friendly    name = name.strip()    name = name.replace(" ", "-")    name = re.sub(r"[^A-Za-z0-9._-]+", "-", name)    name = re.sub(r"-{2,}", "-", name).strip("-")    if not name:        name = "file"    return namedef sha1_file(path):    h = hashlib.sha1()    with open(path, "rb") as f:        for chunk in iter(lambda: f.read(1024 * 1024), b""):            h.update(chunk)    return h.hexdigest()def clipboard_set(text):    try:        p = subprocess.Popen(["pbcopy"], stdin=subprocess.PIPE)        p.communicate(text.encode("utf-8"))    except Exception:        passdef build_repo_path(cfg, local_path):    base = cfg.get("repo_path_prefix", "uploads")    now = dt.datetime.now()    y = now.strftime("%Y")    m = now.strftime("%m")    fname = sanitize_filename(os.path.basename(local_path))    # Optional: include a short hash to avoid collisions    if cfg.get("append_short_hash", True):        short = sha1_file(local_path)[:8]        root, ext = os.path.splitext(fname)        fname = f"{root}-{short}{ext}"    return f"{base}/{y}/{m}/{fname}"def upload_contents_api(cfg, token, local_path, remote_path):    owner = cfg["owner"]    repo = cfg["repo"]    branch = cfg.get("branch", "main")    url = f"https://api.github.com/repos/{owner}/{repo}/contents/{remote_path}"    # Read + base64    with open(local_path, "rb") as f:        blob = f.read()    b64 = base64.b64encode(blob).decode("ascii")    msg = f"Upload {os.path.basename(local_path)} via ghu"    payload = {        "message": msg,        "content": b64,        "branch": branch,    }    resp = api_request("PUT", url, token, data=payload)    # Response includes content.download_url when available    content = resp.get("content") if resp else None    if not content:        raise RuntimeError("GitHub API returned no content object.")    return content.get("download_url"), content.get("html_url")def get_or_create_release(cfg, token):    owner = cfg["owner"]    repo = cfg["repo"]    tag = cfg.get("release_tag", "ghu-uploads")    name = cfg.get("release_name", "Uploads")    draft = bool(cfg.get("release_draft", True))    prerelease = bool(cfg.get("release_prerelease", False))    # Try get by tag    url_get = f"https://api.github.com/repos/{owner}/{repo}/releases/tags/{tag}"    try:        rel = api_request("GET", url_get, token)        return rel["id"], rel["upload_url"]    except Exception:        pass    # Create    url_create = f"https://api.github.com/repos/{owner}/{repo}/releases"    payload = {        "tag_name": tag,        "name": name,        "draft": draft,        "prerelease": prerelease,        "generate_release_notes": False,        "body": "Automated uploads via ghuploader.",    }    rel = api_request("POST", url_create, token, data=payload)    return rel["id"], rel["upload_url"]def upload_release_asset(cfg, token, local_path):    owner = cfg["owner"]    repo = cfg["repo"]    rel_id, upload_url_tmpl = get_or_create_release(cfg, token)    # upload_url looks like: https://uploads.github.com/repos/{owner}/{repo}/releases/{id}/assets{?name,label}    upload_url = upload_url_tmpl.split("{")[0]    fname = sanitize_filename(os.path.basename(local_path))    # avoid collisions with timestamp    if cfg.get("release_append_timestamp", True):        root, ext = os.path.splitext(fname)        fname = f"{root}-{int(time.time())}{ext}"    ctype = mimetypes.guess_type(local_path)[0] or "application/octet-stream"    url = f"{upload_url}?name={urllib.parse.quote(fname)}"    # Use raw curl for binary upload (simple + reliable)    # Authorization header for uploads endpoint still works with Bearer.    auth = f"Authorization: Bearer {token}"    accept = "Accept: application/vnd.github+json"    api_ver = "X-GitHub-Api-Version: 2022-11-28"    cmd = [        "curl", "-sS", "-L",        "-X", "POST",        "-H", accept,        "-H", auth,        "-H", api_ver,        "-H", f"Content-Type: {ctype}",        "--data-binary", f"@{local_path}",        url    ]    out = subprocess.check_output(cmd)    resp = json.loads(out.decode("utf-8"))    # Browser download URL is the most user-friendly    return resp.get("browser_download_url"), resp.get("url")def format_links(cfg, local_path, url):    fname = os.path.basename(local_path)    mode = cfg.get("output_mode", "markdown")  # markdown | url | both    extra_audio = bool(cfg.get("also_audio_html", True))    md = f"[{fname}]({url})"    lines = []    if mode in ("markdown", "both"):        lines.append(md)        # Optional: HTML audio embed for remote audio (Obsidian usually handles HTML fine)        if extra_audio and re.search(r"\.(mp3|m4a|aac|wav|flac|ogg)$", fname, re.IGNORECASE):            lines.append(f'<audio controls src="{url}"></audio>')    if mode in ("url", "both"):        lines.append(url)    return "\n".join(lines)def main(argv):    cfg = load_config()    token = get_token(cfg)    if len(argv) < 2:        eprint("Usage: ghu <file1> [file2 ...]")        sys.exit(2)    max_contents_mb = float(cfg.get("contents_max_mb", 95))    out_blocks = []    for p in argv[1:]:        p = os.path.expanduser(p)        if not os.path.exists(p) or not os.path.isfile(p):            eprint(f"Skip (not a file): {p}")            continue        size_mb = os.path.getsize(p) / (1024 * 1024)        if size_mb <= max_contents_mb:            remote_path = build_repo_path(cfg, p)            url, _html = upload_contents_api(cfg, token, p, remote_path)            if not url:                raise RuntimeError("No download_url returned for contents upload.")            out_blocks.append(format_links(cfg, p, url))        else:            # Release assets support up to 2 GiB per file (GitHub docs)            if os.path.getsize(p) > 2 * 1024 * 1024 * 1024:                raise RuntimeError(f"File too large (>2 GiB): {p}")            url, _api = upload_release_asset(cfg, token, p)            if not url:                raise RuntimeError("No browser_download_url returned for release upload.")            out_blocks.append(format_links(cfg, p, url))    if not out_blocks:        eprint("No files uploaded.")        sys.exit(1)    combined = "\n\n".join(out_blocks).strip() + "\n"    print(combined)    clipboard_set(combined)if __name__ == "__main__":    main(sys.argv)